// import * as utils from './utils.js'
import {drawKeypoints, drawSkeleton} from './utils.js'

var imageScaleFactor = 0.5; // A number between 0.2 and 1.0. Defaults to 0.50. What to scale the image by before feeding it through the network. Set this number lower to scale down the image and increase the speed when feeding through the network at the cost of accuracy.
var outputStride = 16; //  the desired stride for the outputs when feeding the image through the model. Must be 32, 16, 8. Defaults to 16. The higher the number, the faster the performance but slower the accuracy, and visa versa.
var flipHorizontal = false; // Defaults to false. If the poses should be flipped/mirrored horizontally. This should be set to true for videos where the video is by default flipped horizontally (i.e. a webcam), and you want the poses to be returned in the proper orientation.

const videoWidth = 600;
const videoHeight = 500;

// posenet.load().then((net) => console.log(net))

// playSound() if exercise is done incorrectly
function playSound() {
  document.getElementById('buzzer').play()
}

var bb = document.getElementById("buzzerButton")

bb.addEventListener('click', playSound)
//

function isAndroid() {
  return /Android/i.test(navigator.userAgent);
}

function isiOS() {
  return /iPhone|iPad|iPod/i.test(navigator.userAgent);
}

function isMobile() {
  return isAndroid() || isiOS();
}

/**
 * Loads a the camera to be used in the demo
 *
 */
async function setupCamera() {
  if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    throw new Error(
        'Browser API navigator.mediaDevices.getUserMedia not available');
  }

  const video = document.getElementById('video');
  video.width = videoWidth;
  video.height = videoHeight;

  const mobile = isMobile();
  const stream = await navigator.mediaDevices.getUserMedia({
    'audio': false,
    'video': {
      facingMode: 'user',
      width: mobile ? undefined : videoWidth,
      height: mobile ? undefined : videoHeight,
    },
  });
  video.srcObject = stream;

  return new Promise((resolve) => {
    video.onloadedmetadata = () => {
      resolve(video);
    };
  });
}

async function loadVideo() {
  const video = await setupCamera();
  video.play();

  return video;
}

const guiState = {
  // algorithm: 'multi-pose',
  input: {
    mobileNetArchitecture: isMobile() ? '0.50' : '0.75',
    outputStride: 16,
    imageScaleFactor: 0.5,
  },
  singlePoseDetection: {
    minPoseConfidence: 0.1, // entire pose confidence score
    minPartConfidence: 0.5, // keypoint confidence score
  },
  output: {
    showVideo: true,
    showSkeleton: true,
    showPoints: true,
    showBoundingBox: false,
  },
  net: null,
};


// var video = document.querySelector("#video");

// if (navigator.mediaDevices.getUserMedia) {
//   navigator.mediaDevices.getUserMedia({ video: true })
//     .then(function (stream) {
//       video.srcObject = stream;
//     })
//     .catch(function (err) {
//       console.log("Something went wrong!");
//     });
// }

/**
 * Feeds an image to posenet to estimate poses - this is where the magic
 * happens. This function loops with a requestAnimationFrame method.
 */
function detectPoseInRealTime(video, net) {
  const canvas = document.getElementById('output');
  const ctx = canvas.getContext('2d');
  // since images are being fed from a webcam
  const flipHorizontal = true;

  canvas.width = videoWidth;
  canvas.height = videoHeight;

  async function poseDetectionFrame() {
    // if (guiState.changeToArchitecture) {
    //   // Important to purge variables and free up GPU memory
    //   guiState.net.dispose();

    //   // Load the PoseNet model weights for either the 0.50, 0.75, 1.00, or 1.01
    //   // version
    //   guiState.net = await posenet.load(+guiState.changeToArchitecture);

    //   guiState.changeToArchitecture = null;
    // }

    // Begin monitoring code for frames per second
    // stats.begin();

    // Scale an image down to a certain factor. Too large of an image will slow
    // down the GPU
    const imageScaleFactor = guiState.input.imageScaleFactor;
    const outputStride = +guiState.input.outputStride;

    let poses = [];
    let minPoseConfidence;
    let minPartConfidence;
    const pose = await net.estimateSinglePose(
      video, imageScaleFactor, flipHorizontal, outputStride);
    poses.push(pose);

    minPoseConfidence = +guiState.singlePoseDetection.minPoseConfidence;
    minPartConfidence = +guiState.singlePoseDetection.minPartConfidence;
    // switch (guiState.algorithm) {
    //   case 'single-pose':
    //     const pose = await guiState.net.estimateSinglePose(
    //         video, imageScaleFactor, flipHorizontal, outputStride);
    //     poses.push(pose);

    //     minPoseConfidence = +guiState.singlePoseDetection.minPoseConfidence;
    //     minPartConfidence = +guiState.singlePoseDetection.minPartConfidence;
    //     break;
    //   case 'multi-pose':
    //     poses = await guiState.net.estimateMultiplePoses(
    //         video, imageScaleFactor, flipHorizontal, outputStride,
    //         guiState.multiPoseDetection.maxPoseDetections,
    //         guiState.multiPoseDetection.minPartConfidence,
    //         guiState.multiPoseDetection.nmsRadius);

    //     minPoseConfidence = +guiState.multiPoseDetection.minPoseConfidence;
    //     minPartConfidence = +guiState.multiPoseDetection.minPartConfidence;
    //     break;
    // }

    ctx.clearRect(0, 0, videoWidth, videoHeight);

    if (guiState.output.showVideo) {
      ctx.save();
      ctx.scale(-1, 1);
      ctx.translate(-videoWidth, 0);
      ctx.drawImage(video, 0, 0, videoWidth, videoHeight);
      ctx.restore();
    }

    // For each pose (i.e. person) detected in an image, loop through the poses
    // and draw the resulting skeleton and keypoints if over certain confidence
    // scores
    let str = ""
    // poses.forEach((score, keypoints) => {
    //   keypoints.forEach((kp) => {
    //     str = str.concat(kp.toString() + "\n")
    //   })
    // })
    document.getElementById('0_x').innerHTML = "nose X HERE"
    poses.forEach(({score, keypoints}) => {

      let i = -0
      let i_str = i.toString()
      let x = i_str + "_x"
      let y = i_str + "_y"
      let s = i_str + "_score"
      document.getElementById(x).innerHTML = Number.parseFloat(keypoints[0].position.x).toFixed(2)
      document.getElementById(y).innerHTML = Number.parseFloat(keypoints[0].position.y).toFixed(2)
      document.getElementById(s).innerHTML = Number.parseFloat(keypoints[0].score).toFixed(4)

      // for (let i=0; i < keypoints.length; i++) {
      //   let i_str = i.toString()
      //   let x = i_str + "_x"
      //   let y = i_str + "_y"
      //   let score = i_str + "_score"
      //   document.getElementById(x).innerHTML = keypoints[0].position.x
      //   document.getElementById(y).innerHTML = keypoints[0].position.y
      //   document.getElementById(score).innerHTML = keypoints[0].score


      // }

      if (score >= minPoseConfidence) {
        if (guiState.output.showPoints) {
          drawKeypoints(keypoints, minPartConfidence, ctx);
        }
        if (guiState.output.showSkeleton) {
          drawSkeleton(keypoints, minPartConfidence, ctx);
        }
      }

    });

    requestAnimationFrame(poseDetectionFrame);
  }

  poseDetectionFrame();
}


/**
 * Kicks off the demo by loading the posenet model, finding and loading
 * available camera devices, and setting off the detectPoseInRealTime function.
 */
async function bindPage() {
  // Load the PoseNet model weights with architecture 0.75
  const net = await posenet.load(0.75);

  document.getElementById('loading').style.display = 'none';
  document.getElementById('main').style.display = 'block';

  let video;

  try {
    video = await loadVideo();
  } catch (e) {
    let info = document.getElementById('info');
    info.textContent = 'this browser does not support video capture,' +
        'or this device does not have a camera';
    info.style.display = 'block';
    throw e;
  }

  detectPoseInRealTime(video, net);
}

navigator.getUserMedia = navigator.getUserMedia ||
    navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
// kick off the demo
bindPage();
